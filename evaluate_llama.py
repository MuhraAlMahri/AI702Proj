import json
from nltk.translate.bleu_score import sentence_bleu
from collections import Counter

# ğŸ“Œ å…³é”®è¯åˆ—è¡¨
keywords = [
    "contradictory", "contradiction", "conflict", "inconsistent", "inconsistency", "paradox",
    "self-contradictory", "paradoxical", "mutually exclusive", "opposing", "discrepancy", 
    "incongruous", "disagreement", "logical fallacy", "circular reasoning", "doublethink",
    "oxymoron", "ambiguous", "contravening", "discordant", "irreconcilable", "duality",
    "counterintuitive", "contradistinction", "antithetical", "incoherent", "dissonance"
]

# ğŸ“Œ è¯»å–æ¨ç†ç»“æœ
with open("inference_results_llama.json", "r") as f:
    results = json.load(f)

# ğŸ“Œ è¯„ä¼°æŒ‡æ ‡
bleu_scores = []
keyword_counts = Counter()

for item in results:
    ref = item["expected_output"].lower()  # çœŸå®ç­”æ¡ˆ (è½¬å°å†™ï¼Œé˜²æ­¢å¤§å°å†™å½±å“)
    pred = item["model_output"].lower()  # LLaMA ç”Ÿæˆçš„ç­”æ¡ˆ (è½¬å°å†™)

    # 1ï¸âƒ£ è®¡ç®— BLEU åˆ†æ•°
    bleu = sentence_bleu([ref.split()], pred.split())  # ä»¥å•è¯ä¸ºå•ä½è®¡ç®— BLEU
    bleu_scores.append(bleu)

    # 2ï¸âƒ£ è®¡ç®—å…³é”®è¯åŒ¹é…
    found = any(keyword in pred for keyword in keywords)
    if found:
        keyword_counts["recognized"] += 1
    else:
        keyword_counts["missed"] += 1

# ğŸ“Œ è®¡ç®—æœ€ç»ˆåˆ†æ•°
avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0.0
total = keyword_counts["recognized"] + keyword_counts["missed"]
recognition_rate = (keyword_counts["recognized"] / total * 100) if total > 0 else 0.0

# ğŸ“Œ æ‰“å°ç»“æœ
print(f"âœ… è¯„ä¼°å®Œæˆï¼")
print(f"ğŸ”¹ å¹³å‡ BLEU åˆ†æ•°: {avg_bleu:.4f}")
print(f"ğŸ”¹ å…³é”®è¯åŒ¹é…æˆåŠŸçš„æ ·æœ¬: {keyword_counts['recognized']} / {total} ({recognition_rate:.2f}%)")