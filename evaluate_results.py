import os
import json
import pandas as pd
from nltk.translate.bleu_score import sentence_bleu
from collections import Counter
from tqdm import tqdm

# å…³é”®è¯åˆ—è¡¨
keywords = [
    "contradictory", "contradiction", "conflict", "inconsistent", "inconsistency", "paradox",
    "self-contradictory", "paradoxical", "mutually exclusive", "opposing", "discrepancy", 
    "incongruous", "disagreement", "logical fallacy", "circular reasoning", "doublethink",
    "oxymoron", "ambiguous", "contravening", "discordant", "irreconcilable", "duality",
    "counterintuitive", "contradistinction", "antithetical", "incoherent", "dissonance"
]

def evaluate_file(file_path):
    """è¯„ä¼°å•ä¸ªæ–‡ä»¶çš„ç»“æœ"""
    print(f"\nğŸ“Š è¯„ä¼°æ–‡ä»¶: {file_path}")
    
    # è¯»å–ç»“æœæ–‡ä»¶
    if file_path.endswith('.json'):
        with open(file_path, 'r') as f:
            results = json.load(f)
    elif file_path.endswith('.csv'):
        results = pd.read_csv(file_path).to_dict('records')
    else:
        print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
        return None

    # è¯„ä¼°æŒ‡æ ‡
    bleu_scores = []
    keyword_counts = Counter()

    for item in tqdm(results, desc="å¤„ç†ä¸­"):
        ref = item["expected_output"].lower()  # çœŸå®ç­”æ¡ˆ
        pred = item["model_output"].lower()  # æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆ

        # è®¡ç®— BLEU åˆ†æ•°
        bleu = sentence_bleu([ref.split()], pred.split())
        bleu_scores.append(bleu)

        # è®¡ç®—å…³é”®è¯åŒ¹é…
        found = any(keyword in pred for keyword in keywords)
        if 'instruction: analyze the following text in input and determine if they contain contradictions,' in pred:
            found = False
            print('found', found)
        if found:
            keyword_counts["recognized"] += 1
        else:
            keyword_counts["missed"] += 1

    # è®¡ç®—æœ€ç»ˆåˆ†æ•°
    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0.0
    total = keyword_counts["recognized"] + keyword_counts["missed"]
    recognition_rate = (keyword_counts["recognized"] / total * 100) if total > 0 else 0.0

    return {
        "file": os.path.basename(file_path),
        "avg_bleu": avg_bleu,
        "recognized": keyword_counts["recognized"],
        "missed": keyword_counts["missed"],
        "total": total,
        "recognition_rate": recognition_rate
    }

def main():
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
    output_dir = "output/finetuned_qwen"
    
    # è·å–æ‰€æœ‰ç»“æœæ–‡ä»¶
    result_files = []
    for root, _, files in os.walk(output_dir):
        for file in files:
            if file.endswith(('.json', '.csv')):
                result_files.append(os.path.join(root, file))

    if not result_files:
        print(f"âŒ åœ¨ {output_dir} ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°ç»“æœæ–‡ä»¶")
        return

    print(f"ğŸ“‚ æ‰¾åˆ° {len(result_files)} ä¸ªç»“æœæ–‡ä»¶")

    # è¯„ä¼°æ‰€æœ‰æ–‡ä»¶
    results = []
    for file_path in result_files:
        result = evaluate_file(file_path)
        if result:
            results.append(result)

    # æ‰“å°æ±‡æ€»ç»“æœ
    print("\nğŸ“ˆ Evaluation Results Summary:")
    print("-" * 80)
    print(f"{'Filename':<30} {'BLEU Score':<10} {'Recognition Rate':<10} {'Recognized/Total':<15}")
    print("-" * 80)
    
    for result in results:
        print(f"{result['file']:<30} {result['avg_bleu']:.4f}    {result['recognition_rate']:.2f}%    {result['recognized']}/{result['total']}")

if __name__ == "__main__":
    main() 